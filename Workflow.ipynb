{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e11eec56",
   "metadata": {},
   "source": [
    "# I. Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b88dbf1",
   "metadata": {},
   "source": [
    "# 1. Extract Descriptions:\n",
    "Read and parse the compressed JSON file containing metadata about the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fea19c35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6461, 14)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the file\n",
    "file_path = '/Users/souhatifour/Downloads/aggregated_metadata.json.gz'\n",
    "\n",
    "# Open and read the compressed JSON file\n",
    "with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the 'experiments' section\n",
    "experiments = data.get('experiments', {})\n",
    "\n",
    "# Convert to DataFrame :) \n",
    "df = pd.DataFrame.from_dict(experiments, orient='index')\n",
    "\n",
    "df.head(3)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767a6be1",
   "metadata": {},
   "source": [
    "## 2. Filtering Out Entries with 'No Description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "382ab5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6403, 14)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a list of terms/phrases that indicate no description\n",
    "no_description_terms = [\n",
    "    'No description.',\n",
    "    'No description available.',\n",
    "    'N/A',\n",
    "    'Not available',\n",
    "    'none provided',\n",
    "    '',  # Empty strings\n",
    "    None  # Null values\n",
    "]\n",
    "\n",
    "# Filter out rows where the 'description' column matches any of the no_description_terms\n",
    "filtered_df = df[~df['description'].str.strip().isin(no_description_terms)]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabe39d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 6403 descriptions and saved to /Users/souhatifour/Downloads/refinebio_descriptions_filtered.tsv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Extract the 'description' column\n",
    "descriptions = filtered_df['description']\n",
    "\n",
    "# Save the descriptions to a TSV file\n",
    "output_file = '/Users/souhatifour/Downloads/refinebio_descriptions_filtered.tsv'\n",
    "descriptions.to_csv(output_file, sep='\\t', index=False, header=False)\n",
    "\n",
    "print(f\"Extracted {len(descriptions)} descriptions and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2257c4",
   "metadata": {},
   "source": [
    "## 3. Save the Accession Codes to a TSV File (after filtering out studies with no discription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the \"accession code\" column\n",
    "accession_codes = filtered_df['accession_code']\n",
    "\n",
    "# File path where the accession codes will be saved as a tsv\n",
    "output_csv_file = '/Users/souhatifour/Downloads/IDs.tsv'\n",
    "\n",
    "# Save the accession codes to a tsv file\n",
    "accession_codes.to_csv(output_csv_file, header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9578f44",
   "metadata": {},
   "source": [
    "# II. Preprocess the Extracted Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1f1c61",
   "metadata": {},
   "source": [
    "### 1. Preprocess Text Descriptions:\n",
    "Run **txt2onto2.0/src/preprocess.py** script to clean and preprocess the extracted descriptions by removing URLs, specific strings, file names, non-UTF-8 characters, and applying text normalization techniques."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a46897e3",
   "metadata": {},
   "source": [
    "python preprocess_descriptions.py \\\n",
    "    -input refinebio_descriptions_filtered.tsv.txt \\\n",
    "    -out processed_refinebio_descriptions_filtered.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c958e4",
   "metadata": {},
   "source": [
    "**Note:** There are some descriptions that contain new lines (\\n) within them. So each description was being separated by a new line, which resulted in more data rows after preprocessing) -> solution: remove some weird characters like ‘\\n’ an ‘\\n\\n’ from the text descriptions before running the **preprocess.py** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc28e10",
   "metadata": {},
   "source": [
    "# III. Generate Embeddings for Processed Descriptions:\n",
    " used **src/embedding_lookup_table.py** script to generate embeddings for the preprocessed descriptions using a pretrained language model (BiomedBERT)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f65edfe",
   "metadata": {},
   "source": [
    "python embedding_lookup_table.py \\\n",
    "    -input /Users/souhatifour/Downloads/processed_refinebio_descriptions_filtered.tsv \\\n",
    "    -out /Users/souhatifour/Downloads/my_custom_embeddings.npz \\\n",
    "    -model biomedbert_abs \\\n",
    "    -batch_size 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8173cf0",
   "metadata": {},
   "source": [
    "# IV. Run Predictions Using MONDO Model Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f35fda",
   "metadata": {},
   "source": [
    "First, check whether specific MONDO terms are present in the full dataset (including redundant terms) and whether they have at least three associated samples to see if we can train a model for each term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "339b7678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONDO:0011918  (Total: 0 samples)\n",
      "MONDO:0004907  (Total: 2 samples)\n",
      "MONDO:0007156  (Total: 0 samples)\n",
      "MONDO:0008661  (Total: 0 samples)\n",
      "MONDO:0005365  (Total: 2 samples)\n",
      "MONDO:0005420  (Total: 0 samples)\n",
      "MONDO:0005296  (Total: 1 samples)\n",
      "MONDO:0100470  (Total: 0 samples)\n",
      "MONDO:0005441  (Total: 0 samples)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/souhatifour/Downloads/true_label__inst_type=study__task=disease.csv.gz'\n",
    "df2 = pd.read_csv(file_path, compression='gzip', index_col=0)\n",
    "\n",
    "\n",
    "# List of MONDO terms to check\n",
    "mondo_terms = [\n",
    "    \"MONDO:0011918\",\n",
    "    \"MONDO:0004907\",\n",
    "    \"MONDO:0007156\",\n",
    "    \"MONDO:0008661\",\n",
    "    \"MONDO:0005365\",\n",
    "    \"MONDO:0005420\",\n",
    "    \"MONDO:0005296\",\n",
    "    \"MONDO:0100470\",\n",
    "    \"MONDO:0005441\"\n",
    "]\n",
    "\n",
    "# Check if MONDO terms are in the dataset and have at least three samples belonging to them\n",
    "for term in mondo_terms:\n",
    "    if term in df2.columns:\n",
    "        # Count the number of samples with a value of 1 for this MONDO term\n",
    "        count_ones = (df2[term] == 1).sum()\n",
    "        if count_ones >= 3:\n",
    "            print(f\"{term}  (Total: {count_ones} studies)\")\n",
    "        else:\n",
    "            print(f\"{term}  (Total: {count_ones} samples)\")\n",
    "    else:\n",
    "        print(f\"{term} is NOT in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3296104",
   "metadata": {},
   "source": [
    "###### 1. Ensure the following files are ready:\n",
    "- refinebio_descriptions_filtered.tsv\n",
    "- IDs.tsv\n",
    "- my_custom_embeddings.npz\n",
    "- disease_desc_embedding.npz\n",
    "- 18 MONDO model files (MONDO_0004986__model.pkl, MONDO_0008903__model.pkl, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a047dbc7",
   "metadata": {},
   "source": [
    "###### 2. Run Predictions for Each MONDO Model File:\n",
    "Execute the predict.py script for each MONDO model file, updating the model file path in each command:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55f566e1",
   "metadata": {},
   "source": [
    "# Example for MONDO_0004986__model.pkl\n",
    "python predict.py \\\n",
    "    -input /Users/souhatifour/Downloads/processed_refinebio_descriptions.tsv \\\n",
    "    -out /Users/souhatifour/Downloads/prediction_results \\\n",
    "    -id /Users/souhatifour/Downloads/IDs.tsv \\\n",
    "    -input_embed /Users/souhatifour/Downloads/my_custom_embeddings.npz \\\n",
    "    -train_embed /Users/souhatifour/Downloads/disease_desc_embedding.npz \\\n",
    "    -model /Users/souhatifour/Downloads/MONDO_0004986__model.pkl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
